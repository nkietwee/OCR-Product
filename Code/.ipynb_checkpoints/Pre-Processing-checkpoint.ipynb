{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecd5e7d2-f428-45a2-a541-a5a1e9bf0b1d",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9be32df5-5fd0-4075-bdc2-e549e2ee1686",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "from ultralytics import YOLO\n",
    "from skimage.measure import label, regionprops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae02d63a-eb7b-4dcc-a5b2-3c8d67500111",
   "metadata": {},
   "source": [
    "## Pre-processing\n",
    "#### - Change RGB image to grayscale\n",
    "#### - Crop specific picture\n",
    "#### - Resize picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a6a5746-a945-4fee-a64a-d21cdbc1aa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display by matplotlib\n",
    "def display(im_path):\n",
    "    dpi = 80\n",
    "    im_data = plt.imread(im_path)\n",
    "    height, width  = im_data.shape[:2]\n",
    "    figsize = width / float(dpi), height / float(dpi)\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.add_axes([0, 0, 1, 1])\n",
    "    ax.axis('off')\n",
    "    ax.imshow(im_data, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c72d41c-86aa-4ccb-a76f-a93369d69fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display by cv\n",
    "ESC = 27\n",
    "def display_path(path):\n",
    "    if os.path.exists(path) is False:\n",
    "        print(\"file doesn't exist\")\n",
    "        return\n",
    "    img = cv2.imread(path)\n",
    "    if img is None:\n",
    "        print(\"can't open img or doesn't have img\")\n",
    "        return \n",
    "    print(\"Hello\")\n",
    "    cv2.imshow(\"img\", img)\n",
    "    while True:\n",
    "        if cv2.waitKey(1) & 0xFF == ESC: \n",
    "            break\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "830d121a-ef8d-44c0-b291-aface1737f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display by cv\n",
    "ESC = 27\n",
    "def display_img(img):\n",
    "    if img is None:\n",
    "        print(\"can't open img or doesn't have img\")\n",
    "        return \n",
    "    cv2.imshow(\"img\", img)\n",
    "    while True:\n",
    "        if cv2.waitKey(1) & 0xFF == ESC: \n",
    "            break\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e33aa77-78b8-448d-a07c-869037b9d90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list file\n",
    "input_path = \"../Input-test/\"\n",
    "output_path = \"../Output/\"\n",
    "input_files = os.listdir(input_path)\n",
    "# input_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d042a6ea-bdd4-4a66-9eab-7094d0fb23fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get path of all image\n",
    "paths = []\n",
    "for files in input_files:\n",
    "    paths.append(os.path.join(input_path + files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb815991-db07-4cef-8477-c63bd01cfd95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Input-test/6.jpg',\n",
       " '../Input-test/ขวด_รวงข้าว.png',\n",
       " '../Input-test/9.jpg',\n",
       " '../Input-test/ขวด_เนสเล่.jpg',\n",
       " '../Input-test/chang_thh.jpg',\n",
       " '../Input-test/กระป๋อง_สิงห์.png',\n",
       " '../Input-test/8.jpg',\n",
       " '../Input-test/5.jpg',\n",
       " '../Input-test/ขวด_สุราข้าวหอม1.jpg',\n",
       " '../Input-test/1.jpg',\n",
       " '../Input-test/plain-text.png',\n",
       " '../Input-test/ขวด_น้ำดื่มสิงห์.jpg',\n",
       " '../Input-test/ขวด_สุราข้าวหอม3.jpg',\n",
       " '../Input-test/ขวด_สุราข้าวหอม2.jpg',\n",
       " '../Input-test/ขวด_คริสตัล.png',\n",
       " '../Input-test/10.jpg',\n",
       " '../Input-test/2.jpg',\n",
       " '../Input-test/images.jpg',\n",
       " '../Input-test/Chang_beer.jpg']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7663b610-10a5-4acd-9172-57791aa864ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.jpg ขวด_รวงข้าว.png 9.jpg ขวด_เนสเล่.jpg chang_thh.jpg กระป๋อง_สิงห์.png 8.jpg 5.jpg ขวด_สุราข้าวหอม1.jpg 1.jpg plain-text.png ขวด_น้ำดื่มสิงห์.jpg ขวด_สุราข้าวหอม3.jpg ขวด_สุราข้าวหอม2.jpg ขวด_คริสตัล.png 10.jpg 2.jpg images.jpg Chang_beer.jpg\n"
     ]
    }
   ],
   "source": [
    "print(*(path.split('/')[-1] for path in paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc035cd5-c729-4b26-b067-8ea4650066ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop specifc bottle\n",
    "# model = YOLO('yolov5s.pt')\n",
    "model = YOLO('yolov5su.pt')\n",
    "def crop_bottle(image, filename):\n",
    "    print('crop_bottle') \n",
    "    if len(image.shape) == 2:  # Grayscale images have shape (height, width)\n",
    "      image = np.stack(3 * [image], axis=-1) # Convert grayscale to 3-channel grayscale by stacking it 3 times\n",
    "    results = model(image)\n",
    "    res = []\n",
    "    if isinstance(results, list):\n",
    "        for i in range(len(results)): #total of picture\n",
    "            for box in results[i].boxes.data: # total of object in 1 picture\n",
    "                x1, y1, x2, y2, conf, cls = map(float, box)\n",
    "                name = results[i].names[cls]\n",
    "                if name == \"bottle\":\n",
    "                    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "                    img = image[y1:y2, x1:x2]\n",
    "                    res.append(img)\n",
    "\n",
    "                  # # display specific rectangle , name and conf\n",
    "                  #   name = results[i].names[cls]\n",
    "                  #   cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 255), 5)\n",
    "                  #   cv2.putText(image, str(conf), (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                  #   cv2.putText(image, str(name), (50, 200), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                  #   cv2.imwrite(output_path + filename.split('/')[-1] ,image)\n",
    "                    # display_img(image)\n",
    "                 # for check error\n",
    "                # else:\n",
    "                    # x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "                    # img = image[y1:y2, x1:x2]\n",
    "                    # res.append(img)\n",
    "                    # name = results[i].names[cls]\n",
    "                    # cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 255), 5)\n",
    "                    # cv2.putText(image, str(conf), (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                    # cv2.putText(image, str(name), (50, 200), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                    # cv2.imwrite(output_path + filename.split('/')[-1] ,image)\n",
    "                    # print(\"confident less than 0.85\")\n",
    "                    # return(res)\n",
    "        return(res)\n",
    "    else:\n",
    "      print(\"not plate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f840b4cf-d663-4009-842f-9147ccba0de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_localization_8_connect(image, binarization_threshold=128):\n",
    "    _, binary_image = cv2.threshold(image, binarization_threshold, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    labeled_image = label(binary_image, connectivity=2)  # 2 for 8-connectivity\n",
    "\n",
    "    regions = regionprops(labeled_image)\n",
    "    bounding_boxes = [region.bbox for region in regions]\n",
    "    crop = []\n",
    "\n",
    "    output_image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)  # Convert to RGB for visualization\n",
    "    for i, bbox in enumerate(bounding_boxes):\n",
    "        min_row, min_col, max_row, max_col = bbox\n",
    "        area = (max_row - min_row) * (max_col - min_col)\n",
    "        if area > 500:  # Filter out small bounding boxes\n",
    "            cropped_region = image[min_row:max_row, min_col:max_col]\n",
    "            crop.append(cropped_region)\n",
    "    return crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "585c244c-3a68-46f5-9e9b-c695f326d854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crop_bottle\n",
      "\n",
      "0: 192x640 (no detections), 120.6ms\n",
      "Speed: 2.5ms preprocess, 120.6ms inference, 0.6ms postprocess per image at shape (1, 3, 192, 640)\n",
      "crop_bottle\n",
      "\n",
      "0: 640x640 1 bottle, 166.1ms\n",
      "Speed: 3.6ms preprocess, 166.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "crop_bottle\n",
      "\n",
      "0: 416x640 (no detections), 108.9ms\n",
      "Speed: 1.7ms preprocess, 108.9ms inference, 0.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "crop_bottle\n",
      "\n",
      "0: 640x512 1 bottle, 112.0ms\n",
      "Speed: 2.1ms preprocess, 112.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "crop_bottle\n",
      "\n",
      "0: 640x384 1 bottle, 79.9ms\n",
      "Speed: 1.2ms preprocess, 79.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "crop_bottle\n",
      "\n",
      "0: 640x640 2 persons, 1 banana, 133.6ms\n",
      "Speed: 1.7ms preprocess, 133.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "crop_bottle\n",
      "\n",
      "0: 640x640 1 dog, 126.3ms\n",
      "Speed: 1.9ms preprocess, 126.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "crop_bottle\n",
      "\n",
      "0: 512x640 (no detections), 110.1ms\n",
      "Speed: 1.6ms preprocess, 110.1ms inference, 0.6ms postprocess per image at shape (1, 3, 512, 640)\n",
      "crop_bottle\n",
      "\n",
      "0: 640x544 1 bottle, 110.2ms\n",
      "Speed: 2.7ms preprocess, 110.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 544)\n",
      "crop_bottle\n",
      "\n",
      "0: 448x640 (no detections), 94.9ms\n",
      "Speed: 1.5ms preprocess, 94.9ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "crop_bottle\n",
      "\n",
      "0: 384x640 (no detections), 89.9ms\n",
      "Speed: 1.8ms preprocess, 89.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "crop_bottle\n",
      "\n",
      "0: 640x640 1 bottle, 1 vase, 137.2ms\n",
      "Speed: 3.0ms preprocess, 137.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "crop_bottle\n",
      "\n",
      "0: 640x416 3 persons, 1 bottle, 93.7ms\n",
      "Speed: 2.1ms preprocess, 93.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 416)\n",
      "crop_bottle\n",
      "\n",
      "0: 640x480 1 person, 1 bottle, 148.5ms\n",
      "Speed: 1.7ms preprocess, 148.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "crop_bottle\n",
      "\n",
      "0: 640x640 1 bottle, 113.2ms\n",
      "Speed: 1.5ms preprocess, 113.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "crop_bottle\n",
      "\n",
      "0: 512x640 (no detections), 96.9ms\n",
      "Speed: 1.3ms preprocess, 96.9ms inference, 0.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "crop_bottle\n",
      "\n",
      "0: 352x640 1 car, 1 cat, 75.1ms\n",
      "Speed: 1.0ms preprocess, 75.1ms inference, 0.5ms postprocess per image at shape (1, 3, 352, 640)\n",
      "crop_bottle\n",
      "\n",
      "0: 384x640 1 microwave, 1 oven, 80.4ms\n",
      "Speed: 1.1ms preprocess, 80.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "crop_bottle\n",
      "\n",
      "0: 640x384 1 bottle, 1 dining table, 80.5ms\n",
      "Speed: 1.2ms preprocess, 80.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    }
   ],
   "source": [
    "# using append() with a list\n",
    "gray_imgs = []\n",
    "target_size = (100, 100)\n",
    "# cnt = 0\n",
    "for path in paths:\n",
    "    img = cv2.imread(path)\n",
    "    if img is not None:\n",
    "            crop_imgs = crop_bottle(img, path)\n",
    "            for crop_img in crop_imgs: # In case it have more than 1 object\n",
    "                crop_img = cv2.cvtColor(crop_img, cv2.COLOR_BGR2GRAY)\n",
    "                if crop_img is None:\n",
    "                    print(\"Failed to convert\")\n",
    "                    break\n",
    "                # crop specific text in picture\n",
    "                bounding_boxes = text_localization_8_connect(crop_img, binarization_threshold=128)\n",
    "                for i in range(len(bounding_boxes)):\n",
    "                    gray_imgs.append(bounding_boxes[i])\n",
    "                # cnt+=1\n",
    "    else:\n",
    "        print(\"Can't open image\")\n",
    "# print(f'cnt : {cnt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcc5d6e0-a7a7-43a9-ac6a-5322e85481c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(gray_imgs)\n",
    "for i in range(len(gray_imgs)): \n",
    "     # print(gray_imgs[i].shape)\n",
    "    # cv2.imshow(\"image\", gray_imgs[i])\n",
    "    cv2.imwrite(f'../Output/{i}.jpg', gray_imgs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249662f0-1921-4100-a3fb-5ec6aceb1bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths[0].split('/')[-1][:-4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c25eec4-432d-4938-8045-00d75d167838",
   "metadata": {},
   "source": [
    "## Optinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52765598-d394-4e02-8730-888af05a8461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(gray_imgs[0]))\n",
    "# display_img(gray_imgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c58fb7e-6cf2-4490-af85-b2177e774512",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"./Input-test/Chang_beer.jpg\")\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "thresh, im_bw = cv2.threshold(img, 150, 255, cv2.THRESH_BINARY)\n",
    "# kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "# binary_image = cv2.morphologyEx(binary_image, cv2.MORPH_CLOSE, kernel)\n",
    "cv2.imwrite(\"./Input-test/chang_thh.jpg\", im_bw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c10559d-9627-4567-b869-caeb45c8d528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_img(binary_image)\n",
    "display_img(im_bw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "03db57bf-6f82-4ae5-847e-3be3cee7c401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ce0bf212-41b5-4f9c-af15-c47bc57cb1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len[bounding_boxes] : 24\n"
     ]
    }
   ],
   "source": [
    "def text_localization_8_connect(image, binarization_threshold=128):\n",
    "    # Create output directory\n",
    "    # output_dir = os.path.join(\"../Output/\", image_path.split('/')[-1][:-4])\n",
    "    # os.makedirs(output_dir, exist_ok=True)  # Ensure the directory exists\n",
    "    \n",
    "    # Step 1: Load the image in grayscale\n",
    "    # image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)    \n",
    "    # Step 2: Binarize the image (assuming dark text on a light background)\n",
    "    _, binary_image = cv2.threshold(image, binarization_threshold, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Step 3: Perform connected component labeling with 8-connectivity\n",
    "    labeled_image = label(binary_image, connectivity=2)  # 2 for 8-connectivity\n",
    "\n",
    "    # Step 4: Extract bounding boxes for each connected component\n",
    "    regions = regionprops(labeled_image)\n",
    "    bounding_boxes = [region.bbox for region in regions]\n",
    "    crop = []\n",
    "    # Step 5: Draw bounding boxes on the original image and save regions\n",
    "    output_image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)  # Convert to RGB for visualization\n",
    "    for i, bbox in enumerate(bounding_boxes):\n",
    "        min_row, min_col, max_row, max_col = bbox\n",
    "        area = (max_row - min_row) * (max_col - min_col)\n",
    "        # if area > 4000:  # Filter out small bounding boxes\n",
    "        if area > 500:  # Filter out small bounding boxes\n",
    "            \n",
    "            # print(f\"Saving region {i} with area {area}\")\n",
    "            # Draw bounding box on the original image\n",
    "            # cv2.rectangle(output_image, (min_col, min_row), (max_col, max_row), (0, 255, 0), 2)\n",
    "            \n",
    "            # Crop the region and save as a new image\n",
    "            cropped_region = image[min_row:max_row, min_col:max_col]\n",
    "            crop.append(cropped_region)\n",
    "            # output_path = os.path.join(output_dir, f\"region_{i}.png\")\n",
    "            # print(f\"Output path: {output_path}\")\n",
    "            # if not cv2.imwrite(output_path, cropped_region):\n",
    "            #     print(f\"Failed to save {output_path}\")\n",
    "    return crop\n",
    "# # Step 6: Display the results\n",
    "# plt.figure(figsize=(12, 6))\n",
    "    \n",
    "# # Original grayscale image\n",
    "# plt.subplot(1, 3, 1)\n",
    "# plt.title(\"Original Image\")\n",
    "# plt.imshow(image, cmap=\"gray\")\n",
    "# plt.axis(\"off\")\n",
    "    \n",
    "# # Binary image\n",
    "# plt.subplot(1, 3, 2)\n",
    "# plt.title(\"Binary Image\")\n",
    "# plt.imshow(binary_image, cmap=\"gray\")\n",
    "# plt.axis(\"off\")\n",
    "    \n",
    "# # Labeled image with bounding boxes\n",
    "# plt.subplot(1, 3, 3)\n",
    "# plt.title(\"Text Localization (Bounding Boxes)\")\n",
    "# plt.imshow(cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB))  # Convert BGR to RGB\n",
    "# plt.axis(\"off\")\n",
    "    \n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "    \n",
    "# return bounding_boxes\n",
    "\n",
    "# Example Usage\n",
    "# image_path = \"../Input-test/ขวด_สุราข้าวหอม3.jpg\"  # Replace with your image path\n",
    "# image_path = \"../Input-test/ขวด_คริสตัล.png\"  # Replace with your image path\n",
    "# image_path = \"../Input-test/Chang_beer.jpg\"  # Replace with your image path\n",
    "# image_path = \"../Input-test/ขวด_รวงข้าว.png\"  # Replace with your image path\n",
    "image_path = \"../Input-test/ขวด_สุราข้าวหอม2.jpg\"  # Replace with your image path\n",
    "# image_path = \"../Input-test/ขวด_สุราข้าวหอม3.jpg\"  # Replace with your image path\n",
    "\n",
    "# bounding_boxes = text_localization_8_connect(image_path, binarization_threshold=128)\n",
    "# img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "img = cv2.imread(image_path)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# if img is None:\n",
    "        # print(\"Failed to load image. Check the path.\")\n",
    "        # return []\n",
    "# image\n",
    "# bounding_boxes = text_localization_8_connect(img, binarization_threshold=128)\n",
    "\n",
    "# print(f'len[bounding_boxes] : {len(bounding_boxes)}')\n",
    "# print(f'bounding_boxes : {bounding_boxes}')\n",
    "# for i in range(len(bounding_boxes)):\n",
    "#     cv2.imshow(\"image\", bounding_boxes[i])\n",
    "#     # cv2.imwrite(\"im\", bounding_boxes[i])\n",
    "#     cv2.waitKey(0)\n",
    "\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ef54985-b73c-4d87-bc2a-57398c96f902",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     43\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal Image\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 44\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(\u001b[43mimage\u001b[49m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     45\u001b[0m plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Binary image\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def text_localization_8_connect(image_path, binarization_threshold=128):\n",
    "    # Create output directory\n",
    "    output_dir = os.path.join(\"../Output/\", image_path.split('/')[-1][:-4])\n",
    "    os.makedirs(output_dir, exist_ok=True)  # Ensure the directory exists\n",
    "\n",
    "    # Step 1: Load the image in grayscale\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        print(\"Failed to load image. Check the path.\")\n",
    "        return []\n",
    "\n",
    "    # Step 2: Binarize the image (assuming dark text on a light background)\n",
    "    _, binary_image = cv2.threshold(image, binarization_threshold, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Step 3: Perform connected component labeling with 8-connectivity\n",
    "    labeled_image = label(binary_image, connectivity=2)  # 2 for 8-connectivity\n",
    "\n",
    "    # Step 4: Extract bounding boxes for each connected component\n",
    "    regions = regionprops(labeled_image)\n",
    "    bounding_boxes = [region.bbox for region in regions]\n",
    "\n",
    "    # Step 5: Draw bounding boxes on the original image and save regions\n",
    "    output_image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)  # Convert to RGB for visualization\n",
    "    for i, bbox in enumerate(bounding_boxes):\n",
    "        min_row, min_col, max_row, max_col = bbox\n",
    "        area = (max_row - min_row) * (max_col - min_col)\n",
    "        if area > 4000:  # Filter out small bounding boxes\n",
    "            print(f\"Saving region {i} with area {area}\")\n",
    "            # Draw bounding box on the original image\n",
    "            cv2.rectangle(output_image, (min_col, min_row), (max_col, max_row), (0, 255, 0), 2)\n",
    "\n",
    "            # Crop the region and save as a new image\n",
    "            cropped_region = image[min_row:max_row, min_col:max_col]\n",
    "            output_path = os.path.join(output_dir, f\"region_{i}.png\")\n",
    "            print(f\"Output path: {output_path}\")\n",
    "            if not cv2.imwrite(output_path, cropped_region):\n",
    "                print(f\"Failed to save {output_path}\")\n",
    "# Step 6: Display the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "    \n",
    "# Original grayscale image\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "    \n",
    "# Binary image\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Binary Image\")\n",
    "plt.imshow(binary_image, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "    \n",
    "# Labeled image with bounding boxes\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Text Localization (Bounding Boxes)\")\n",
    "plt.imshow(cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB))  # Convert BGR to RGB\n",
    "plt.axis(\"off\")\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "    \n",
    "return bounding_boxes\n",
    "\n",
    "# Example Usage\n",
    "# image_path = \"../Input-test/ขวด_สุราข้าวหอม3.jpg\"  # Replace with your image path\n",
    "# image_path = \"../Input-test/ขวด_คริสตัล.png\"  # Replace with your image path\n",
    "# image_path = \"../Input-test/Chang_beer.jpg\"  # Replace with your image path\n",
    "# image_path = \"../Input-test/ขวด_รวงข้าว.png\"  # Replace with your image path\n",
    "image_path = \"../Input-test/ขวด_สุราข้าวหอม3.jpg\"  # Replace with your image path\n",
    "\n",
    "# bounding_boxes = text_localization_8_connect(image_path, binarization_threshold=128)\n",
    "\n",
    "# image\n",
    "bounding_boxes = text_localization_8_connect(image_path, binarization_threshold=128)\n",
    "\n",
    "# Print the bounding boxes\n",
    "# print(f\"Detected Bounding Boxes: {bounding_boxes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e2a862-0203-4e86-a8d3-415c60637c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"../Input-test/Chang_beer.jpg\"\n",
    "path = \"../Input-test/6.jpg\"\n",
    "image = cv2.imread(path)\n",
    "results = model(image)\n",
    "print(f'result :  {len(results)}')\n",
    "print(\"------------------------------------------------------------------\")\n",
    "# print(results)\n",
    "print(\"------------------------------------------------------------------\")\n",
    "for i in range(len(results)): #total of picture\n",
    "    print(f'|len : {len(results[i])}|')\n",
    "    if len(results[i]) == 0:\n",
    "           print(f'res : {results[i].boxes.data}')\n",
    "    for box in results[i].boxes.data: # total of object in 1 picture\n",
    "        print(\"Entry\")\n",
    "        x1, y1, x2, y2, conf, cls = map(float, box)\n",
    "        name = results[i].names[cls]\n",
    "        if name == \"bottle\":\n",
    "            print(f'name : {name}')\n",
    "            print(f'conf : {conf}')\n",
    "        else :\n",
    "            print(f'name : {name}')\n",
    "            print(f'conf : {conf}')\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096bc129-9301-4dd7-938b-edb44131f468",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
