{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecd5e7d2-f428-45a2-a541-a5a1e9bf0b1d",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9be32df5-5fd0-4075-bdc2-e549e2ee1686",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "from ultralytics import YOLO\n",
    "from skimage.measure import label, regionprops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae02d63a-eb7b-4dcc-a5b2-3c8d67500111",
   "metadata": {},
   "source": [
    "## Pre-processing\n",
    "#### - Change RGB image to grayscale\n",
    "#### - Crop specific picture\n",
    "#### - Resize picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a6a5746-a945-4fee-a64a-d21cdbc1aa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display by matplotlib\n",
    "def display(im_path):\n",
    "    dpi = 80\n",
    "    im_data = plt.imread(im_path)\n",
    "    height, width  = im_data.shape[:2]\n",
    "    figsize = width / float(dpi), height / float(dpi)\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.add_axes([0, 0, 1, 1])\n",
    "    ax.axis('off')\n",
    "    ax.imshow(im_data, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c72d41c-86aa-4ccb-a76f-a93369d69fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display by cv\n",
    "ESC = 27\n",
    "def display_path(path):\n",
    "    if os.path.exists(path) is False:\n",
    "        print(\"file doesn't exist\")\n",
    "        return\n",
    "    img = cv2.imread(path)\n",
    "    if img is None:\n",
    "        print(\"can't open img or doesn't have img\")\n",
    "        return \n",
    "    print(\"Hello\")\n",
    "    cv2.imshow(\"img\", img)\n",
    "    while True:\n",
    "        if cv2.waitKey(1) & 0xFF == ESC: \n",
    "            break\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "830d121a-ef8d-44c0-b291-aface1737f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display by cv\n",
    "ESC = 27\n",
    "def display_img(img):\n",
    "    if img is None:\n",
    "        print(\"can't open img or doesn't have img\")\n",
    "        return \n",
    "    cv2.imshow(\"img\", img)\n",
    "    while True:\n",
    "        if cv2.waitKey(1) & 0xFF == ESC: \n",
    "            break\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e33aa77-78b8-448d-a07c-869037b9d90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list file\n",
    "input_path = \"../Input-test/\"\n",
    "output_path = \"../Output/\"\n",
    "input_files = os.listdir(input_path)\n",
    "# input_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d042a6ea-bdd4-4a66-9eab-7094d0fb23fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get path of all image\n",
    "paths = []\n",
    "for files in input_files:\n",
    "    paths.append(os.path.join(input_path + files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb815991-db07-4cef-8477-c63bd01cfd95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Input-test/6.jpg',\n",
       " '../Input-test/ขวด_รวงข้าว.png',\n",
       " '../Input-test/9.jpg',\n",
       " '../Input-test/ขวด_เนสเล่.jpg',\n",
       " '../Input-test/chang_thh.jpg',\n",
       " '../Input-test/กระป๋อง_สิงห์.png',\n",
       " '../Input-test/8.jpg',\n",
       " '../Input-test/5.jpg',\n",
       " '../Input-test/ขวด_สุราข้าวหอม1.jpg',\n",
       " '../Input-test/1.jpg',\n",
       " '../Input-test/plain-text.png',\n",
       " '../Input-test/ขวด_น้ำดื่มสิงห์.jpg',\n",
       " '../Input-test/ขวด_สุราข้าวหอม3.jpg',\n",
       " '../Input-test/ขวด_สุราข้าวหอม2.jpg',\n",
       " '../Input-test/ขวด_คริสตัล.png',\n",
       " '../Input-test/10.jpg',\n",
       " '../Input-test/2.jpg',\n",
       " '../Input-test/images.jpg',\n",
       " '../Input-test/Chang_beer.jpg']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7663b610-10a5-4acd-9172-57791aa864ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.jpg ขวด_รวงข้าว.png 9.jpg ขวด_เนสเล่.jpg chang_thh.jpg กระป๋อง_สิงห์.png 8.jpg 5.jpg ขวด_สุราข้าวหอม1.jpg 1.jpg plain-text.png ขวด_น้ำดื่มสิงห์.jpg ขวด_สุราข้าวหอม3.jpg ขวด_สุราข้าวหอม2.jpg ขวด_คริสตัล.png 10.jpg 2.jpg images.jpg Chang_beer.jpg\n"
     ]
    }
   ],
   "source": [
    "print(*(path.split('/')[-1] for path in paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dc035cd5-c729-4b26-b067-8ea4650066ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop specifc bottle\n",
    "# model = YOLO('yolov5s.pt')\n",
    "model = YOLO('yolov5su.pt')\n",
    "def crop_bottle(image, filename):\n",
    "    print('crop_bottle') \n",
    "    if len(image.shape) == 2:  # Grayscale images have shape (height, width)\n",
    "      image = np.stack(3 * [image], axis=-1) # Convert grayscale to 3-channel grayscale by stacking it 3 times\n",
    "    results = model(image)\n",
    "    res = []\n",
    "    if isinstance(results, list):\n",
    "        for i in range(len(results)): #total of picture\n",
    "            for box in results[i].boxes.data: # total of object in 1 picture\n",
    "                x1, y1, x2, y2, conf, cls = map(float, box)\n",
    "                name = results[i].names[cls]\n",
    "                if name == \"bottle\":\n",
    "                    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "                    img = image[y1:y2, x1:x2]\n",
    "                    res.append(img)\n",
    "\n",
    "                  # # display specific rectangle , name and conf\n",
    "                  #   name = results[i].names[cls]\n",
    "                  #   cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 255), 5)\n",
    "                  #   cv2.putText(image, str(conf), (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                  #   cv2.putText(image, str(name), (50, 200), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                  #   cv2.imwrite(output_path + filename.split('/')[-1] ,image)\n",
    "                    # display_img(image)\n",
    "                 # for check error\n",
    "                # else:\n",
    "                    # x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "                    # img = image[y1:y2, x1:x2]\n",
    "                    # res.append(img)\n",
    "                    # name = results[i].names[cls]\n",
    "                    # cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 255), 5)\n",
    "                    # cv2.putText(image, str(conf), (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                    # cv2.putText(image, str(name), (50, 200), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                    # cv2.imwrite(output_path + filename.split('/')[-1] ,image)\n",
    "                    # print(\"confident less than 0.85\")\n",
    "                    # return(res)\n",
    "        return(res)\n",
    "    else:\n",
    "      print(\"not plate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "585c244c-3a68-46f5-9e9b-c695f326d854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crop_bottle\n",
      "\n",
      "0: 192x640 (no detections), 3.4ms\n",
      "Speed: 1.1ms preprocess, 3.4ms inference, 0.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "crop_bottle\n",
      "\n",
      "0: 640x640 1 bottle, 7.4ms\n",
      "Speed: 1.4ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "crop_bottle\n",
      "\n",
      "0: 416x640 (no detections), 5.3ms\n",
      "Speed: 0.8ms preprocess, 5.3ms inference, 0.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "crop_bottle\n",
      "\n",
      "0: 640x512 1 bottle, 5.9ms\n",
      "Speed: 1.5ms preprocess, 5.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "crop_bottle\n",
      "\n",
      "0: 640x384 1 bottle, 5.3ms\n",
      "Speed: 5.1ms preprocess, 5.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "crop_bottle\n",
      "\n",
      "0: 640x640 2 persons, 1 banana, 7.3ms\n",
      "Speed: 2.0ms preprocess, 7.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "crop_bottle\n",
      "\n",
      "0: 640x640 1 dog, 6.9ms\n",
      "Speed: 1.3ms preprocess, 6.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "crop_bottle\n",
      "\n",
      "0: 512x640 (no detections), 7.9ms\n",
      "Speed: 1.0ms preprocess, 7.9ms inference, 0.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "crop_bottle\n",
      "\n",
      "0: 640x544 1 bottle, 6.0ms\n",
      "Speed: 1.9ms preprocess, 6.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 544)\n",
      "crop_bottle\n",
      "\n",
      "0: 448x640 (no detections), 5.5ms\n",
      "Speed: 1.1ms preprocess, 5.5ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "crop_bottle\n",
      "\n",
      "0: 384x640 (no detections), 5.1ms\n",
      "Speed: 1.4ms preprocess, 5.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "crop_bottle\n",
      "\n",
      "0: 640x640 1 bottle, 1 vase, 7.5ms\n",
      "Speed: 1.6ms preprocess, 7.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "crop_bottle\n",
      "\n",
      "0: 640x416 3 persons, 1 bottle, 5.3ms\n",
      "Speed: 1.3ms preprocess, 5.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 416)\n",
      "crop_bottle\n",
      "\n",
      "0: 640x480 1 person, 1 bottle, 6.1ms\n",
      "Speed: 1.7ms preprocess, 6.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "crop_bottle\n",
      "\n",
      "0: 640x640 1 bottle, 7.2ms\n",
      "Speed: 1.4ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "crop_bottle\n",
      "\n",
      "0: 512x640 (no detections), 5.7ms\n",
      "Speed: 1.0ms preprocess, 5.7ms inference, 0.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "crop_bottle\n",
      "\n",
      "0: 352x640 1 car, 1 cat, 5.1ms\n",
      "Speed: 0.8ms preprocess, 5.1ms inference, 0.6ms postprocess per image at shape (1, 3, 352, 640)\n",
      "crop_bottle\n",
      "\n",
      "0: 384x640 1 microwave, 1 oven, 5.1ms\n",
      "Speed: 0.9ms preprocess, 5.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "crop_bottle\n",
      "\n",
      "0: 640x384 1 bottle, 1 dining table, 5.0ms\n",
      "Speed: 1.2ms preprocess, 5.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    }
   ],
   "source": [
    "# using append() with a list\n",
    "gray_imgs = []\n",
    "target_size = (100, 100)\n",
    "# cnt = 0\n",
    "for path in paths:\n",
    "    img = cv2.imread(path)\n",
    "    if img is not None:\n",
    "            crop_imgs = crop_bottle(img, path)\n",
    "            for crop_img in crop_imgs: # In case it have more than 1 object\n",
    "                # bounding_boxes = text_localization_8_connect(crop_img, binarization_threshold=128)\n",
    "                # print(f\"path :  {path}\")\n",
    "                # gray_imgs.append(bounding_boxes)\n",
    "                gray_imgs.append(crop_img)\n",
    "                # cnt+=1ห\n",
    "    else:\n",
    "        print(\"Can't open image\")\n",
    "# print(f'cnt : {cnt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dcc5d6e0-a7a7-43a9-ac6a-5322e85481c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(414, 117, 3)\n",
      "(196, 57, 3)\n",
      "(362, 193, 3)\n",
      "(1265, 351, 3)\n",
      "(482, 144, 3)\n",
      "(1872, 811, 3)\n",
      "(1476, 486, 3)\n",
      "(507, 143, 3)\n",
      "(758, 203, 3)\n"
     ]
    }
   ],
   "source": [
    "# len(gray_imgs)\n",
    "for i in range(len(gray_imgs)):\n",
    "     print(gray_imgs[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "249662f0-1921-4100-a3fb-5ec6aceb1bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths[0].split('/')[-1][:-4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c25eec4-432d-4938-8045-00d75d167838",
   "metadata": {},
   "source": [
    "## Optinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52765598-d394-4e02-8730-888af05a8461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(gray_imgs[0]))\n",
    "# display_img(gray_imgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c58fb7e-6cf2-4490-af85-b2177e774512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(\"./Input-test/Chang_beer.jpg\")\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "thresh, im_bw = cv2.threshold(img, 150, 255, cv2.THRESH_BINARY)\n",
    "# kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "# binary_image = cv2.morphologyEx(binary_image, cv2.MORPH_CLOSE, kernel)\n",
    "cv2.imwrite(\"./Input-test/chang_thh.jpg\", im_bw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c10559d-9627-4567-b869-caeb45c8d528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_img(binary_image)\n",
    "display_img(im_bw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9ef54985-b73c-4d87-bc2a-57398c96f902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_localization_8_connect(image, binarization_threshold=128):\n",
    "    # Create output directory\n",
    "    # output_dir = os.path.join(\"../Output/\", image_path.split('/')[-1][:-4])\n",
    "    # os.makedirs(output_dir, exist_ok=True)  # Ensure the directory exists\n",
    "\n",
    "    # Step 1: Load the image in grayscale\n",
    "    # image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    # if image is None:\n",
    "    #     print(\"Failed to load image. Check the path.\")\n",
    "    #     return []\n",
    "\n",
    "    # Step 2: Binarize the image (assuming dark text on a light background)\n",
    "    _, binary_image = cv2.threshold(image, binarization_threshold, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Step 3: Perform connected component labeling with 8-connectivity\n",
    "    labeled_image = label(binary_image, connectivity=2)  # 2 for 8-connectivity\n",
    "\n",
    "    # Step 4: Extract bounding boxes for each connected component\n",
    "    regions = regionprops(labeled_image)\n",
    "    bounding_boxes = [region.bbox for region in regions]\n",
    "\n",
    "    # Step 5: Draw bounding boxes on the original image and save regions\n",
    "    # output_image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)  # Convert to RGB for visualization\n",
    "    for i, bbox in enumerate(bounding_boxes):\n",
    "        min_row, min_col, max_row, max_col = bbox\n",
    "        area = (max_row - min_row) * (max_col - min_col)\n",
    "        if area > 4000:  # Filter out small bounding boxes\n",
    "            print(f\"Saving region {i} with area {area}\")\n",
    "            # Draw bounding box on the original image\n",
    "            cv2.rectangle(output_image, (min_col, min_row), (max_col, max_row), (0, 255, 0), 2)\n",
    "\n",
    "            # Crop the region and save as a new image\n",
    "            cropped_region = image[min_row:max_row, min_col:max_col]\n",
    "            output_path = os.path.join(output_dir, f\"region_{i}.png\")\n",
    "            print(f\"Output path: {output_path}\")\n",
    "            if not cv2.imwrite(output_path, cropped_region):\n",
    "                print(f\"Failed to save {output_path}\")\n",
    "        # Step 6: Display the results\n",
    "        plt.figure(figsize=(12, 6))\n",
    "    \n",
    "        # Original grayscale image\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.title(\"Original Image\")\n",
    "        plt.imshow(image, cmap=\"gray\")\n",
    "        plt.axis(\"off\")\n",
    "    \n",
    "        # Binary image\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.title(\"Binary Image\")\n",
    "        plt.imshow(binary_image, cmap=\"gray\")\n",
    "        plt.axis(\"off\")\n",
    "    \n",
    "        # Labeled image with bounding boxes\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.title(\"Text Localization (Bounding Boxes)\")\n",
    "        plt.imshow(cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB))  # Convert BGR to RGB\n",
    "        plt.axis(\"off\")\n",
    "    \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "        return bounding_boxes\n",
    "\n",
    "# Example Usage\n",
    "# image_path = \"../Input-test/ขวด_สุราข้าวหอม3.jpg\"  # Replace with your image path\n",
    "# image_path = \"../Input-test/ขวด_คริสตัล.png\"  # Replace with your image path\n",
    "# image_path = \"../Input-test/Chang_beer.jpg\"  # Replace with your image path\n",
    "# image_path = \"../Input-test/ขวด_รวงข้าว.png\"  # Replace with your image path\n",
    "# image_path = \"../Input-test/ขวด_สุราข้าวหอม3.jpg\"  # Replace with your image path\n",
    "\n",
    "# bounding_boxes = text_localization_8_connect(image_path, binarization_threshold=128)\n",
    "\n",
    "image\n",
    "bounding_boxes = text_localization_8_connect(image_path, binarization_threshold=128)\n",
    "\n",
    "# Print the bounding boxes\n",
    "# print(f\"Detected Bounding Boxes: {bounding_boxes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e9e2a862-0203-4e86-a8d3-415c60637c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 192x640 (no detections), 3.9ms\n",
      "Speed: 9.5ms preprocess, 3.9ms inference, 0.3ms postprocess per image at shape (1, 3, 192, 640)\n",
      "result :  1\n",
      "------------------------------------------------------------------\n",
      "------------------------------------------------------------------\n",
      "|len : 0|\n",
      "res : tensor([], device='cuda:0', size=(0, 6))\n"
     ]
    }
   ],
   "source": [
    "# path = \"../Input-test/Chang_beer.jpg\"\n",
    "path = \"../Input-test/6.jpg\"\n",
    "image = cv2.imread(path)\n",
    "results = model(image)\n",
    "print(f'result :  {len(results)}')\n",
    "print(\"------------------------------------------------------------------\")\n",
    "# print(results)\n",
    "print(\"------------------------------------------------------------------\")\n",
    "for i in range(len(results)): #total of picture\n",
    "    print(f'|len : {len(results[i])}|')\n",
    "    if len(results[i]) == 0:\n",
    "           print(f'res : {results[i].boxes.data}')\n",
    "    for box in results[i].boxes.data: # total of object in 1 picture\n",
    "        print(\"Entry\")\n",
    "        x1, y1, x2, y2, conf, cls = map(float, box)\n",
    "        name = results[i].names[cls]\n",
    "        if name == \"bottle\":\n",
    "            print(f'name : {name}')\n",
    "            print(f'conf : {conf}')\n",
    "        else :\n",
    "            print(f'name : {name}')\n",
    "            print(f'conf : {conf}')\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096bc129-9301-4dd7-938b-edb44131f468",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
